{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Networks - Final Project\n",
    "\n",
    "\"Is there an optimal road or road structure to close and convert to a public use space in Barcelona that minimizes the impact on traffic?\"\n",
    "\n",
    "-Clarice Mottet, Amber Walker, Mox Ballo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General Notes:\n",
    "\n",
    "There are only 930 nodes in the link_file, there are 2522 edges in the link_file (haven't checked for duplicates). There are no duplicate edges (based on origin_node to to_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "website link that the frank wolfe code is from\n",
    "\n",
    "https://nbviewer.org/github/PyTrans/Urban-Network-Analysis/blob/master/Trip_Assignment-Frank-Wolfe_Algorithm.ipynb\n",
    "\n",
    "website link that the TransportationNetworks code is from\n",
    "\n",
    "https://github.com/PyTrans/Urban-Network-Analysis/tree/master/pytrans/UrbanNetworkAnalysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SUPER IMPORTANT\n",
    "\n",
    "I saw in the TransportationNetworks.py file that their initial alpha was .5 but everywhere said it should be .15, so I changed it to .15 in my file.\n",
    "\n",
    "Because there is no node_file and I have to create it, I had to alter some of the TransportationNetworks.py code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import scipy.integrate as integrate \n",
    "from scipy.optimize import minimize_scalar\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.misc import derivative\n",
    "# import TransportationNetworks as tn\n",
    "\n",
    "# import os\n",
    "# os.chdir('/content/drive/My Drive/networks_final_project_collab/networks_finalproject')\n",
    "\n",
    "import TransportationNetworks_CM as tncm\n",
    "\n",
    "# path_in_ = r'./inputs/'\n",
    "# path_out_ = r'./outputs'\n",
    "# path_out_nash_ = r'./outputs/results'\n",
    "\n",
    "path_in_ = r'/home/clarice/Documents/VSCode/Term2_Networks/final_project/networks_finalproject/inputs/'\n",
    "path_out_ = r'/home/clarice/Documents/VSCode/Term2_Networks/final_project/networks_finalproject/outputs/'\n",
    "path_out_nash_ = r'/home/clarice/Documents/VSCode/Term2_Networks/final_project/networks_finalproject/outputs/nash_equilibrium_flow/'\n",
    "path_out_social_ = r'/home/clarice/Documents/VSCode/Term2_Networks/final_project/networks_finalproject/outputs/social_optimum_flow/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions: user, based on jupyter notebook\n",
    "\n",
    "#from website to calculate latency\n",
    "def BPR(t0, xa, ca, alpha, beta):\n",
    "    ta = t0*(1+alpha*(xa/ca)**beta)\n",
    "    return ta\n",
    "\n",
    "#from website: method to calculate nash equilibrium (when SO = False)\n",
    "def calculateZ(theta, network, SO):\n",
    "    z = 0\n",
    "    for linkKey, linkVal in network.items():\n",
    "        t0 = linkVal['t0']\n",
    "        ca = linkVal['capa']\n",
    "        beta = linkVal['beta']\n",
    "        alpha = linkVal['alpha']\n",
    "        aux = linkVal['auxiliary'][-1]\n",
    "        flow = linkVal['flow'][-1]\n",
    "        \n",
    "        if SO == False:\n",
    "            z += integrate.quad(lambda x: BPR(t0, x, ca, alpha, beta), 0, flow+theta*(aux-flow))[0]\n",
    "        elif SO == True:\n",
    "            z += list(map(lambda x : x * BPR(t0, x, ca, alpha, beta), [flow+theta*(aux-flow)]))[0]\n",
    "    return z\n",
    "\n",
    "#from website: finds nash equilibrium\n",
    "def lineSearch(network, SO):\n",
    "    theta = minimize_scalar(lambda x: calculateZ(x, network, SO), bounds = (0,1), method = 'Bounded')\n",
    "    return theta.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions: user, based on jupyter notebook\n",
    "\n",
    "def initialize(link_file, trip_file, od_vols, origins, od_dic, links, graph, SO):\n",
    "    #set objective and open the network\n",
    "    barcelonaSubset = tncm.Network(link_file, trip_file, od_vols, origins, od_dic, links, graph)\n",
    "\n",
    "    #CM - start of initialization\n",
    "\n",
    "    # define output variables, network and fwResult\n",
    "    network = {(u,v): {'t0':d['object'].t0, 'alpha':d['object'].alpha, \\\n",
    "            'beta':d['object'].beta, 'capa':d['object'].capacity, 'flow':[], \\\n",
    "            'auxiliary':[], 'cost':[]} for (u, v, d) in barcelonaSubset.graph.edges(data=True)}\n",
    "\n",
    "    fwResult = {'theta':[], 'z':[]}\n",
    "\n",
    "    # initial all-or-nothing assignment and update link travel time(cost)\n",
    "    barcelonaSubset.all_or_nothing_assignment()\n",
    "    barcelonaSubset.update_linkcost()\n",
    "\n",
    "    for linkKey, linkVal in network.items():\n",
    "        linkVal['cost'].append(barcelonaSubset.graph[linkKey[0]][linkKey[1]]['weight'])\n",
    "        linkVal['auxiliary'].append(barcelonaSubset.graph[linkKey[0]][linkKey[1]]['object'].vol)\n",
    "        linkVal['flow'].append(barcelonaSubset.graph[linkKey[0]][linkKey[1]]['object'].vol)\n",
    "\n",
    "    return barcelonaSubset, network, fwResult\n",
    "\n",
    "#frank wolfe algorithm function\n",
    "def frank_wolfe(barcelonaSubset, network, fwResult, SO):\n",
    "    ## iterations\n",
    "    iterNum=0\n",
    "    iteration = True\n",
    "    while iteration:\n",
    "        iterNum += 1\n",
    "        barcelonaSubset.all_or_nothing_assignment()\n",
    "        barcelonaSubset.update_linkcost()\n",
    "        \n",
    "        # set auxiliary flow using updated link flow\n",
    "        for linkKey, linkVal in network.items():\n",
    "            linkVal['auxiliary'].append(barcelonaSubset.graph[linkKey[0]][linkKey[1]]['object'].vol)\n",
    "            \n",
    "        # getting optimal move size (theta)\n",
    "        theta = lineSearch(network, SO)\n",
    "        fwResult['theta'].append(theta)\n",
    "        \n",
    "        # set link flow (move) based on the theta, auxiliary flow, and link flow of previous iteration\n",
    "        for linkKey, linkVal in network.items():\n",
    "            aux = linkVal['auxiliary'][-1]\n",
    "            flow = linkVal['flow'][-1]\n",
    "            linkVal['flow'].append(flow + theta*(aux-flow))\n",
    "            \n",
    "            barcelonaSubset.graph[linkKey[0]][linkKey[1]]['object'].vol =  flow + theta * (aux - flow)\n",
    "            barcelonaSubset.graph[linkKey[0]][linkKey[1]]['object'].flow = flow + theta * (aux - flow)\n",
    "            \n",
    "        # update link travel time\n",
    "        barcelonaSubset.update_linkcost()\n",
    "        \n",
    "        # calculate objective function value\n",
    "        z=0\n",
    "        for linkKey, linkVal in network.items():\n",
    "            linkVal['cost'].append(barcelonaSubset.graph[linkKey[0]][linkKey[1]]['weight'])\n",
    "            totalcost = barcelonaSubset.graph[linkKey[0]][linkKey[1]]['object'].get_objective_function()\n",
    "            z+=totalcost\n",
    "            \n",
    "        fwResult['z'].append(z)        \n",
    "            \n",
    "        # convergence test\n",
    "        if iterNum == 1:\n",
    "            iteration = True\n",
    "        else:\n",
    "            if abs(fwResult['z'][-2] - fwResult['z'][-1]) <= 0.001 or iterNum==3000:\n",
    "                iteration = False\n",
    "\n",
    "    return barcelonaSubset, network, fwResult\n",
    "\n",
    "def cash_overall(network):\n",
    "    overall_travel_time = 0.0\n",
    "    overall_total_cost = 0.0\n",
    "\n",
    "    for (u, v, d) in network.graph.edges(data=True):\n",
    "        link_obj = d['object']\n",
    "        current_flow = link_obj.flow  # Assuming this gives the final flow\n",
    "        t0 = link_obj.t0\n",
    "        c = link_obj.capacity\n",
    "        alpha = link_obj.alpha\n",
    "        beta = link_obj.beta\n",
    "        # Calculate the travel time with the final flow\n",
    "        travel_time = BPR(t0, current_flow, c, alpha, beta)\n",
    "        overall_travel_time += travel_time\n",
    "        # Optionally calculate total cost (travel time * flow)\n",
    "        total_cost = travel_time * current_flow\n",
    "        overall_total_cost += total_cost\n",
    "        # Update the network with the new travel time and total cost\n",
    "        network.graph[u][v]['travel_time'] = travel_time\n",
    "        network.graph[u][v]['total_cost'] = total_cost\n",
    "    return network, overall_travel_time, overall_total_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions: user - based on TransportationNetworks\n",
    "\n",
    "def open_trip_file_CM(trip_file):\n",
    "    demand_factor=1.0\n",
    "    f = open(trip_file)\n",
    "    lines = f.readlines()\n",
    "    f.close()\n",
    "\n",
    "    od_vols = {}\n",
    "    current_origin = None\n",
    "\n",
    "    for line in lines:\n",
    "        if current_origin == None and line.startswith(\"Origin\"):\n",
    "            origin = str(int(line.split(\"Origin\")[1]))\n",
    "            current_origin = origin\n",
    "\n",
    "        elif current_origin != None and len(line) < 3:\n",
    "            # print \"blank\",line,\n",
    "            current_origin = None\n",
    "\n",
    "        elif current_origin != None:\n",
    "            to_process = line[0:-2]\n",
    "            for el in to_process.split(\";\"):\n",
    "                try:\n",
    "                    dest = str(int(el.split(\":\")[0]))\n",
    "                    demand = float(el.split(\":\")[1]) * demand_factor\n",
    "                    od_vols[current_origin, dest] = demand\n",
    "                except:\n",
    "                    continue\n",
    "    origins = [str(i) for i, j in od_vols]\n",
    "    origins = list(dict.fromkeys(origins).keys())\n",
    "\n",
    "    od_dic = {}\n",
    "    for (origin, destination) in od_vols:\n",
    "        if origin not in od_dic:\n",
    "            od_dic[origin] = {}\n",
    "\n",
    "        od_dic[origin][destination] = od_vols[origin, destination]\n",
    "    return od_vols, origins, od_dic\n",
    "\n",
    "\n",
    "def open_link_file_CM(link_file, SO):\n",
    "    link_fields = {\"from\": 1, \"to\": 2, \"capacity\": 3, \"length\": 4, \"t0\": 5, \\\n",
    "                    \"B\": 6, \"beta\": 7, \"V\": 8}\n",
    "    f = open(link_file)\n",
    "    lines = f.readlines()\n",
    "    f.close()\n",
    "\n",
    "    links_info = []\n",
    "\n",
    "    header_found = False\n",
    "    for line in lines:\n",
    "        if not header_found and line.startswith(\"~\"):\n",
    "            header_found = True\n",
    "        elif header_found:\n",
    "            links_info.append(line)\n",
    "\n",
    "    nodes = {}\n",
    "    links = []\n",
    "\n",
    "    for line in links_info:\n",
    "        data = line.split(\"\\t\")\n",
    "\n",
    "        try:\n",
    "            origin_node = str(int(data[link_fields[\"from\"]]))\n",
    "        except IndexError:\n",
    "            continue\n",
    "        to_node = str(int(data[link_fields[\"to\"]]))\n",
    "        capacity = float(data[link_fields[\"capacity\"]])\n",
    "        length = float(data[link_fields[\"length\"]])\n",
    "        alpha = float(data[link_fields[\"B\"]])\n",
    "        beta = float(data[link_fields[\"beta\"]])\n",
    "\n",
    "        if origin_node not in nodes:\n",
    "            n = tncm.Node(node_id=origin_node)\n",
    "            nodes[origin_node] = n\n",
    "\n",
    "        if to_node not in nodes:\n",
    "            n = tncm.Node(node_id=to_node)\n",
    "            nodes[to_node] = n\n",
    "\n",
    "        l = tncm.Link(link_id=len(links), length=length, capacity=capacity, alpha=alpha, beta=beta,\n",
    "                    from_node=origin_node, to_node=to_node, flow=float(0.0), SO=SO)\n",
    "\n",
    "        links.append(l)\n",
    "    return links\n",
    "    \n",
    "def build_datastructure_CM(links):        \n",
    "    graph = nx.DiGraph()\n",
    "\n",
    "    for l in links:\n",
    "        graph.add_edge(l.get_from_node(), l.get_to_node(), object=l, time=l.get_time())\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions: user, scratch\n",
    "\n",
    "#used in the identify superblocks code\n",
    "def common_rmv_round(graph, neighbors_node_, common_node):\n",
    "    for node_ in neighbors_node_:\n",
    "        neighbors_node__ = list(graph.neighbors(node_))\n",
    "        for node_common in common_node:\n",
    "            if node_common in neighbors_node__:\n",
    "                common_node.append(node_)\n",
    "                common_node = list(set(list(common_node)))\n",
    "                if node_ in neighbors_node_:\n",
    "                    neighbors_node_.remove(node_)        \n",
    "    return neighbors_node_, common_node\n",
    "\n",
    "\n",
    "def identify_superblocks_directed(graph_directed, dict_blocks):\n",
    "    dict_blocks_directed = {}\n",
    "\n",
    "    for iter_ in dict_blocks.keys():\n",
    "        list_center = dict_blocks[iter_][0]\n",
    "        list_corner = dict_blocks[iter_][1]\n",
    "        list_outside = dict_blocks[iter_][2]\n",
    "\n",
    "        #make sure that removing the edges to the center doesn't cause issues to the outside nodes\n",
    "        #like if an outside node is only degree 2 and then one edge is removed and its an origin node\n",
    "        #so the cars can't leave the node\n",
    "        dict_outside_degree = {}\n",
    "        for node_center in list_center:\n",
    "            dict_outside_degree[node_center] = []\n",
    "            for node in list_outside:\n",
    "                edge_in_exists = graph_directed.has_edge(node_center, node)\n",
    "                edge_out_exists = graph_directed.has_edge(node, node_center)\n",
    "                if ((graph_directed.in_degree(node)-int(edge_in_exists)) >= 1)&((graph_directed.out_degree(node)-int(edge_out_exists)) >= 1):\n",
    "                    dict_outside_degree[node_center].append(node)\n",
    "        \n",
    "        outside_clear = 0\n",
    "        for node_center in list_center:\n",
    "            if len(dict_outside_degree[node_center])==len(list_outside):\n",
    "                outside_clear += 1\n",
    "                \n",
    "        list_corner_degree = []\n",
    "        #make sure that there are at least two nodes on the corners that have\n",
    "        #in degree > 1 and out degree > 1\n",
    "        for node in list_corner:\n",
    "            if (graph_directed.in_degree(node) >= 1)&(graph_directed.out_degree(node) >= 1):\n",
    "                list_corner_degree.append(node)\n",
    "\n",
    "        if (len(list_corner_degree) >= 2)&(outside_clear==4):\n",
    "            dict_blocks_directed[iter_] = [list_center, list_corner, list_outside, list_corner_degree]\n",
    "\n",
    "    return dict_blocks_directed\n",
    "\n",
    "\n",
    "#function that identifies superblocks in an undirected graph\n",
    "def identify_superblocks(graph_directed):\n",
    "    graph = nx.Graph(graph_directed)\n",
    "    list_nodes = list(graph.nodes)\n",
    "\n",
    "    dict_blocks = {}\n",
    "    iter_ = 0\n",
    "\n",
    "    for node_i in list_nodes:\n",
    "        # for node_i in list_nodes:\n",
    "        neighbors_i = list(graph.neighbors(node_i))\n",
    "        neighbors_i_ = list(graph.neighbors(node_i))\n",
    "        nodes_common = []\n",
    "        for node_j in neighbors_i:\n",
    "            neighbors_j = list(graph.neighbors(node_j))\n",
    "            neighbors_j.remove(node_i)\n",
    "            neighbors_i_.remove(node_j)\n",
    "            #make sure that you remove common neighbors in neighbors_j\n",
    "            for node_j_ in neighbors_i:\n",
    "                if node_j != node_j_:\n",
    "                    neighbors_j_ = list(graph.neighbors(node_j_))\n",
    "                    for element in neighbors_j_:\n",
    "                        if element in neighbors_j:\n",
    "                            neighbors_j.remove(element)\n",
    "                            nodes_common.append(element)\n",
    "                            nodes_common = list(set(list(nodes_common)))\n",
    "            #continue to next node\n",
    "            for node_k in neighbors_j:\n",
    "                neighbors_k = list(graph.neighbors(node_k))\n",
    "                neighbors_k.remove(node_j)\n",
    "                #remove common neighbors\n",
    "                neighbors_k, nodes_common = common_rmv_round(graph, neighbors_k, nodes_common)\n",
    "                for node_l in neighbors_k:\n",
    "                    neighbors_l = list(graph.neighbors(node_l))\n",
    "                    neighbors_l.remove(node_k)\n",
    "                    #now we have (node_i, node_j, node_k, node_l)\n",
    "                    #go to row 2\n",
    "                    for node_m in neighbors_i_:\n",
    "                        #we don't want node_j to equal node_m\n",
    "                        neighbors_m = list(graph.neighbors(node_m))\n",
    "                        neighbors_m.remove(node_i)\n",
    "                        for node_n in neighbors_m:\n",
    "                            neighbors_n = list(graph.neighbors(node_n))\n",
    "                            neighbors_n.remove(node_m)\n",
    "                            for node_o in neighbors_n:\n",
    "                                if node_o != node_j:\n",
    "                                    neighbors_o = list(graph.neighbors(node_o))\n",
    "                                    neighbors_o.remove(node_n)\n",
    "                                    for node_p in neighbors_o:\n",
    "                                        if node_p != node_k:\n",
    "                                            neighbors_p = list(graph.neighbors(node_p))\n",
    "                                            neighbors_p.remove(node_o)\n",
    "                                            #now we have (node_m, node_n, node_o, node_p)\n",
    "                                            #if first row is connected to second row\n",
    "                                            if (node_j in neighbors_n)&(node_k in neighbors_o)&(node_l in neighbors_p):\n",
    "                                                #continue to third row\n",
    "                                                for node_q in neighbors_m:\n",
    "                                                    neighbors_q = list(graph.neighbors(node_q))\n",
    "                                                    neighbors_q.remove(node_m)\n",
    "                                                    for node_r in neighbors_q:\n",
    "                                                        neighbors_r = list(graph.neighbors(node_r))\n",
    "                                                        neighbors_r.remove(node_q)\n",
    "                                                        for node_s in neighbors_r:\n",
    "                                                            if node_s != node_n:\n",
    "                                                                neighbors_s = list(graph.neighbors(node_s))\n",
    "                                                                neighbors_s.remove(node_r)\n",
    "                                                                for node_t in neighbors_s:\n",
    "                                                                    if node_t !=node_o:\n",
    "                                                                        neighbors_t = list(graph.neighbors(node_t))\n",
    "                                                                        neighbors_t.remove(node_s)\n",
    "                                                                        if (node_n in neighbors_r)&(node_o in neighbors_s)&(node_p in neighbors_t):\n",
    "                                                                            #now we have (node_q, node_r, node_s, node_t)\n",
    "                                                                            # print(\"third row\",node_q, node_r, node_s, node_t)\n",
    "                                                                            for node_w in neighbors_q:\n",
    "                                                                                neighbors_w = list(graph.neighbors(node_w))\n",
    "                                                                                neighbors_w.remove(node_q)\n",
    "                                                                                for node_x in neighbors_w:\n",
    "                                                                                    neighbors_x = list(graph.neighbors(node_x))\n",
    "                                                                                    neighbors_x.remove(node_w)\n",
    "                                                                                    for node_y in neighbors_x:\n",
    "                                                                                        neighbors_y = list(graph.neighbors(node_y))\n",
    "                                                                                        neighbors_y.remove(node_x)\n",
    "                                                                                        for node_z in neighbors_y:\n",
    "                                                                                            if node_z != node_s:\n",
    "                                                                                                neighbors_z = list(graph.neighbors(node_z))\n",
    "                                                                                                neighbors_z.remove(node_y)\n",
    "                                                                                                if (node_r in neighbors_x)&(node_s in neighbors_y)&(node_t in neighbors_z):\n",
    "                                                                                                    #document all the nodes                                                                \n",
    "                                                                                                    list_center = [node_n, node_o, node_r, node_s]\n",
    "                                                                                                    list_corner = [node_i, node_l, node_w, node_z]\n",
    "                                                                                                    list_outside = [node_i, node_j, node_k, node_l, node_m, node_p, node_q, node_t, node_w, node_x, node_y, node_z]\n",
    "\n",
    "                                                                                                    list_center.sort()\n",
    "                                                                                                    list_corner.sort()\n",
    "                                                                                                    list_outside.sort()\n",
    "\n",
    "                                                                                                    #make sure no duplicate nodes    \n",
    "                                                                                                    list_center = list(set(list_center))\n",
    "                                                                                                    list_outside = list(set(list_outside))\n",
    "\n",
    "                                                                                                    #check that all nodes are degree 4\n",
    "                                                                                                    all_nodes_degree4 = 0\n",
    "                                                                                                    # for node in list_outside:\n",
    "                                                                                                    #     if graph.degree[node] > 3:\n",
    "                                                                                                    #         all_nodes_degree4 += 1\n",
    "                                                                                                    for node in list_center:\n",
    "                                                                                                        if graph.degree[node] == 4:\n",
    "                                                                                                            all_nodes_degree4 += 1\n",
    "                                                                                                    \n",
    "                                                                                                    if all_nodes_degree4 == 4:\n",
    "                                                                                                        # print(\"all nodes are degree 4\")\n",
    "                                                                                                        #check to make sure that the same graph isn't being added again\n",
    "                                                                                                        are_equal = 0\n",
    "                                                                                                        for prev in dict_blocks.keys():\n",
    "                                                                                                            if (dict_blocks[prev][0] == list_center)&(dict_blocks[prev][2] == list_outside):\n",
    "                                                                                                                are_equal += 1\n",
    "                                                                                                        if are_equal == 0:\n",
    "                                                                                                            #add the new superblock to the dictionary\n",
    "                                                                                                            # print(iter_)\n",
    "                                                                                                            dict_blocks[iter_] = [list_center, list_corner, list_outside]\n",
    "                                                                                                            iter_ += 1\n",
    "    print(\"Number of superblocks\",len(dict_blocks.keys()))\n",
    "    dict_blocks_directed = identify_superblocks_directed(graph_directed, dict_blocks)\n",
    "    print(\"Number of superblocks directed\",len(dict_blocks_directed.keys()))\n",
    "    return dict_blocks_directed, dict_blocks\n",
    "\n",
    "#this is code that updates the trips file by removing a superblock\n",
    "def update_od_vols(list_dict_blocks_directed_iter, od_vols):\n",
    "    list_center = list_dict_blocks_directed_iter[0]\n",
    "    list_corner_degree = list_dict_blocks_directed_iter[3]\n",
    "\n",
    "    in_corner_node = list_corner_degree[0]\n",
    "    out_corner_node = list_corner_degree[1]\n",
    "\n",
    "    #make a copy\n",
    "    od_vols_out = {}\n",
    "    for key_ in od_vols.keys():\n",
    "        od_vols_out[key_] = od_vols[key_]\n",
    "\n",
    "    #compile the relevant \n",
    "    origin_demand_center = []\n",
    "    dest_demand_center = []\n",
    "    for key_ in od_vols_out.keys():\n",
    "        for node_center in list_center:\n",
    "            #compile the center starting nodes\n",
    "            if str(node_center) == key_[0]:\n",
    "                origin_demand_center.append(key_)\n",
    "            #compile the in node replacement\n",
    "            if str(node_center) == key_[1]:\n",
    "                dest_demand_center.append(key_)\n",
    "\n",
    "    #update the origin connections\n",
    "    for connection in origin_demand_center:\n",
    "        #create an update connection\n",
    "        if (str(in_corner_node) == connection[1])|(int(connection[1]) in list_center):\n",
    "            update_connection = (str(in_corner_node),str(out_corner_node))\n",
    "        else:\n",
    "            update_connection = (str(in_corner_node),connection[1])\n",
    "        if update_connection in list(od_vols_out.keys()):\n",
    "            od_vols_out[update_connection] += od_vols_out[connection]\n",
    "        else:\n",
    "            od_vols_out[update_connection] = od_vols[connection]\n",
    "        del od_vols_out[connection]\n",
    "\n",
    "    for connection in dest_demand_center:\n",
    "        if connection not in origin_demand_center:\n",
    "            #create an update connection\n",
    "            if (str(out_corner_node) == connection[0])|(int(connection[0]) in list_center):\n",
    "                update_connection = (str(in_corner_node),str(out_corner_node))\n",
    "            else:\n",
    "                update_connection = (connection[0], str(out_corner_node))\n",
    "            if update_connection in list(od_vols_out.keys()):\n",
    "                od_vols_out[update_connection] += od_vols_out[connection]\n",
    "            else:\n",
    "                od_vols_out[update_connection] = od_vols_out[connection]\n",
    "            del od_vols_out[connection]\n",
    "\n",
    "    return od_vols_out\n",
    "\n",
    "def update_trip(list_dict_blocks_directed_iter, trip_file):\n",
    "    od_vols, origins, od_dic = open_trip_file_CM(trip_file)\n",
    "    od_vols_out = update_od_vols(list_dict_blocks_directed_iter, od_vols)\n",
    "\n",
    "    del origins, od_dic\n",
    "\n",
    "    origins = [str(i) for i, j in od_vols_out]\n",
    "    origins = list(dict.fromkeys(origins).keys())\n",
    "\n",
    "    od_dic = {}\n",
    "    for (origin, destination) in od_vols_out:\n",
    "        if origin not in od_dic:\n",
    "            od_dic[origin] = {}\n",
    "\n",
    "        od_dic[origin][destination] = od_vols_out[origin, destination]\n",
    "    return od_vols_out, origins, od_dic\n",
    "\n",
    "#remove edges of the center nodes of the super block\n",
    "def update_links(list_dict_blocks_directed_iter, link_file, SO):\n",
    "    links_out = open_link_file_CM(link_file, SO)\n",
    "    list_center = list_dict_blocks_directed_iter[0]\n",
    "\n",
    "    #delete all edges tied to the center nodes of the superblock\n",
    "    remove_link_index = []\n",
    "\n",
    "    for i, l in enumerate(links_out):\n",
    "        if (l.get_from_node() in list_center)|(l.get_to_node() in list_center):\n",
    "            remove_link_index.append(i)\n",
    "\n",
    "    remove_link_index.sort(reverse = True)\n",
    "    for i in remove_link_index:\n",
    "        del links_out[i]\n",
    "    \n",
    "    return links_out\n",
    "\n",
    "def graph_w_superblock(graph, list_center, list_outside, seed):\n",
    "    # Prepare node colors\n",
    "    node_colors = []\n",
    "    for node in graph.nodes():\n",
    "        if node in list_center:\n",
    "            node_colors.append('green')\n",
    "        elif node in list_outside:\n",
    "            node_colors.append('purple') \n",
    "        else:\n",
    "            node_colors.append('blue')\n",
    "\n",
    "    # Generate a layout\n",
    "    pos = nx.spring_layout(graph, scale=1, seed = seed)\n",
    "    # pos = nx.spring_layout(graph, scale=2, seed = 42)\n",
    "\n",
    "    # Set figure size\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    # plt.figure(figsize=(20, 20))\n",
    "\n",
    "    # Draw the graph with specified node colors\n",
    "    nx.draw_networkx(graph, pos, arrows=True, node_size=20, width=0.1, with_labels=False, alpha=0.7, node_color=node_colors)\n",
    "\n",
    "    # Adjust plot\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data into programming environment\n",
    "directory = path_in_\n",
    "link_file = '{}Barcelona_net.tntp'.format(path_in_)\n",
    "trip_file = '{}Barcelona_trips.tntp'.format(path_in_)\n",
    "\n",
    "od_vols, origins, od_dic = open_trip_file_CM(trip_file)\n",
    "links = open_link_file_CM(link_file, False)\n",
    "graph = build_datastructure_CM(links)\n",
    "#to be able to access stuff in graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of superblocks 87\n",
      "Number of superblocks directed 87\n"
     ]
    }
   ],
   "source": [
    "#Identify all eligible superblocks in the barcelona network\n",
    "\n",
    "dict_superblocks, dict_blocks_ignore = identify_superblocks(graph)\n",
    "\n",
    "df_superblocks = pd.DataFrame(dict_superblocks)\n",
    "df_superblocks = df_superblocks.transpose()\n",
    "df_superblocks.reset_index(inplace = True)\n",
    "df_superblocks.columns = ['iter_','list_center','list_corner','list_outside','list_corner_degree']\n",
    "# df_superblocks.to_excel(path_out_+'df_superblocks_social.xlsx', index = False)\n",
    "\n",
    "df_blocks_ignore = pd.DataFrame(dict_blocks_ignore)\n",
    "df_blocks_ignore = df_blocks_ignore.transpose()\n",
    "df_blocks_ignore.reset_index(inplace = True)\n",
    "df_blocks_ignore.columns = ['iter_','list_center','list_corner','list_outside']\n",
    "# df_blocks_ignore.to_excel(path_out_+'df_blocks_all_social.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of center nodes 348\n",
      "number of center nodes 167\n"
     ]
    }
   ],
   "source": [
    "dist_number_of_center = []\n",
    "for iter_ in dict_superblocks.keys():\n",
    "    list_center = dict_superblocks[iter_][0]\n",
    "    for node in list_center:\n",
    "        dist_number_of_center.append(node)\n",
    "print(\"number of center nodes\",len(dist_number_of_center))\n",
    "dist_number_of_center = list(set(dist_number_of_center))\n",
    "print(\"number of center nodes\",len(dist_number_of_center))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of outside nodes 1044\n",
      "number of outside nodes 322\n"
     ]
    }
   ],
   "source": [
    "dist_number_of_outside = []\n",
    "for iter_ in dict_superblocks.keys():\n",
    "    list_center = dict_superblocks[iter_][2]\n",
    "    for node in list_center:\n",
    "        dist_number_of_outside.append(node)\n",
    "print(\"number of outside nodes\",len(dist_number_of_outside))\n",
    "dist_number_of_outside = list(set(dist_number_of_outside))\n",
    "print(\"number of outside nodes\",len(dist_number_of_outside))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_remove = []\n",
    "\n",
    "for node_ in dist_number_of_center:\n",
    "    for i, node_out in enumerate(dist_number_of_outside):\n",
    "        if node_ == node_out:\n",
    "            index_remove.append(i)\n",
    "\n",
    "index_remove.sort(reverse = True)\n",
    "for i in index_remove:\n",
    "    del dist_number_of_outside[i]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_center = dist_number_of_center\n",
    "list_outside = dist_number_of_outside\n",
    "\n",
    "# graph_w_superblock(graph, list_center, list_outside, 40)\n",
    "# graph_w_superblock(graph, list_center, list_outside, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_center = dist_number_of_center\n",
    "list_outside = dist_number_of_outside\n",
    "\n",
    "origins_int = [int(node_) for node_ in origins]\n",
    "\n",
    "# graph_w_superblock(graph, list_center, origins_int, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #calculate the total cost for the graph on the whole - nash equilibrium\n",
    "\n",
    "# #initialize graph\n",
    "# barcelonaSubset, network, fwResult = initialize(link_file, trip_file, od_vols, origins, od_dic, links, graph, False)\n",
    "\n",
    "# #use frank-wolfe to find nash equilibrium\n",
    "# barcelonaSubset, network, fwResult = frank_wolfe(barcelonaSubset, network, fwResult, False)\n",
    "\n",
    "# #calculate latency\n",
    "# barcelonaSubset, overall_travel_time, overall_total_cost = cash_overall(barcelonaSubset)\n",
    "\n",
    "# df_out = pd.DataFrame([[-1, overall_travel_time, overall_total_cost]], columns = ['block_iter','overall_travel_time','overall_total_cost'])\n",
    "# # df_out.to_excel(path_out_nash_+'df_cost_base'+'.xlsx', index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run through dictionary of superblocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_superblocks\n",
    "\n",
    "# list_ran = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #for loop through the dictionary of super blocks\n",
    "# SO = False\n",
    "\n",
    "# # dict_superblocks.keys()\n",
    "# for iter_ in dict_superblocks.keys():\n",
    "#     print(iter_)\n",
    "#     if iter_ not in list_ran:\n",
    "#         #remove the super block from the graph\n",
    "#         od_vols_out, origins_out, od_dic_out = update_trip(dict_superblocks[iter_], trip_file)\n",
    "#         links_out = update_links(dict_superblocks[iter_], link_file, SO)\n",
    "\n",
    "#         #initialize graph\n",
    "#         barcelonaSubset, network, fwResult = initialize(link_file, trip_file, od_vols_out, origins_out, od_dic_out, links_out, graph, SO)\n",
    "\n",
    "#         #use frank-wolfe to find nash equilibrium\n",
    "#         barcelonaSubset, network, fwResult = frank_wolfe(barcelonaSubset, network, fwResult, SO)\n",
    "\n",
    "#         #calculate latency\n",
    "#         barcelonaSubset, overall_travel_time, overall_total_cost = cash_overall(barcelonaSubset)\n",
    "\n",
    "#         df_out = pd.DataFrame([[iter_, overall_travel_time, overall_total_cost]], columns = ['block_iter','overall_travel_time','overall_total_cost'])\n",
    "#         # df_out.to_excel(path_out_nash_+'df_nash_cost_'+str(iter_)+'.xlsx', index = False)\n",
    "#         list_ran.append(iter_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import time\n",
    "\n",
    "# #calculate the total cost for the graph on the whole - social equilibrium\n",
    "# SO = True\n",
    "\n",
    "# start_time = time.time()\n",
    "\n",
    "# #initialize graph\n",
    "# barcelonaSubset, network, fwResult = initialize(link_file, trip_file, od_vols, origins, od_dic, links, graph, SO)\n",
    "\n",
    "# #use frank-wolfe to find nash equilibrium\n",
    "# barcelonaSubset, network, fwResult = frank_wolfe(barcelonaSubset, network, fwResult, SO)\n",
    "\n",
    "# #calculate latency\n",
    "# barcelonaSubset, overall_travel_time, overall_total_cost = cash_overall(barcelonaSubset)\n",
    "\n",
    "# df_out = pd.DataFrame([[-1, overall_travel_time, overall_total_cost]], columns = ['block_iter','overall_travel_time','overall_total_cost'])\n",
    "# df_out.to_excel(path_out_social_+'df_cost_base_social_'+'.xlsx', index = False)\n",
    "\n",
    "# end_time = time.time()\n",
    "# print(\"amount of time for one run\", end_time - start_time)\n",
    "# #4212"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_ran = []\n",
    "\n",
    "# SO = True\n",
    "\n",
    "# # dict_superblocks.keys() - social equilibrium\n",
    "# for iter_ in dict_superblocks.keys():\n",
    "#     print(iter_)\n",
    "#     if (iter_ not in list_ran) & (iter_ > 42) & (iter_ < 56):\n",
    "#         #remove the super block from the graph\n",
    "#         od_vols_out, origins_out, od_dic_out = update_trip(dict_superblocks[iter_], trip_file)\n",
    "#         links_out = update_links(dict_superblocks[iter_], link_file, SO)\n",
    "\n",
    "#         #initialize graph\n",
    "#         barcelonaSubset, network, fwResult = initialize(link_file, trip_file, od_vols_out, origins_out, od_dic_out, links_out, graph, SO)\n",
    "\n",
    "#         #use frank-wolfe to find nash equilibrium\n",
    "#         barcelonaSubset, network, fwResult = frank_wolfe(barcelonaSubset, network, fwResult, SO)\n",
    "\n",
    "#         #calculate latency\n",
    "#         barcelonaSubset, overall_travel_time, overall_total_cost = cash_overall(barcelonaSubset)\n",
    "\n",
    "#         df_out = pd.DataFrame([[iter_, overall_travel_time, overall_total_cost]], columns = ['block_iter','overall_travel_time','overall_total_cost'])\n",
    "#         df_out.to_excel(path_out_social_+'df_social_cost_'+str(iter_)+'.xlsx', index = False)\n",
    "#         list_ran.append(iter_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_out_nash_ = r'/home/clarice/Documents/VSCode/Term2_Networks/final_project/networks_finalproject/outputs/nash_equilibrium_flow/'\n",
    "path_out_social_ = r'/home/clarice/Documents/VSCode/Term2_Networks/final_project/networks_finalproject/outputs/social_optimum_flow/'\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
